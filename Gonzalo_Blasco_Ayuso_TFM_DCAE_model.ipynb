{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage import exposure\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANT VARIABLES\n",
    "\n",
    "ROOT_FOLDER = # INCLUDE PATH TO ROOT FOLDER\n",
    "DATASET_FOLDER = # INCLUDE NAME OF DATASET ROOT FOLDER\n",
    "DEFECT_TYPE_FOLDER = # INCLUDE NAME OF DEFECT TYPE FOLDER\n",
    "IMG_SIZE = (256, 256) # not too big or might run out of memory\n",
    "COLOR_IMAGES = False\n",
    "INPUT_SHAPE = (256, 256, 3 if COLOR_IMAGES else 1)\n",
    "SEG_OUTPUT_SIZE = (256, 256) # same as input shape for this network\n",
    "\n",
    "LATENT_DIM = 100 # z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMAGE TRANSFORMATIONS\n",
    "\n",
    "# Crop the center of an image\n",
    "def crop_center_opencv(image, crop_width, crop_height):\n",
    "    height, width = image.shape[:2]\n",
    "    start_x = width // 2 - (crop_width // 2)\n",
    "    start_y = height // 2 - (crop_height // 2)\n",
    "    cropped_image = image[start_y:start_y + crop_height, start_x:start_x + crop_width]\n",
    "    return cropped_image\n",
    "\n",
    "# Load reference image for contrast\n",
    "def load_ref_img_contrast(img_size=IMG_SIZE):\n",
    "    for filename in os.listdir(os.path.join(ROOT_FOLDER, DATASET_FOLDER, DEFECT_TYPE_FOLDER, \"test_normal\")):\n",
    "        img_path = os.path.join(os.path.join(ROOT_FOLDER, DATASET_FOLDER, DEFECT_TYPE_FOLDER, \"test_normal\"), filename)\n",
    "        img = cv2.imread(img_path, cv2.COLOR_BGR2RGB if COLOR_IMAGES else cv2.IMREAD_GRAYSCALE)  # Convert to RGB/grey scale\n",
    "        img = cv2.resize(img, img_size)  # Resize to desired dimensions\n",
    "        img = img.astype(np.float32) / 255.0  # Normalize to [0, 1]\n",
    "        return img\n",
    "        \n",
    "\n",
    "# Load images from a folder\n",
    "def load_images_from_folder(folder, img_size=IMG_SIZE):\n",
    "    images = []\n",
    "    filenames = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img_path = os.path.join(folder, filename)\n",
    "\n",
    "        img = cv2.imread(img_path, cv2.COLOR_BGR2RGB if COLOR_IMAGES else cv2.IMREAD_GRAYSCALE)  # Convert to RGB/grey scale\n",
    "        img = cv2.resize(img, img_size)  # Resize to desired dimensions\n",
    "        img = img.astype(np.float32) / 255.0  # Normalize to [0, 1]  \n",
    "             \n",
    "        img = exposure.equalize_adapthist(img, clip_limit=0.01)\n",
    "        #img = exposure.equalize_hist(img)\n",
    " \n",
    "        img = img if COLOR_IMAGES else np.expand_dims(img, axis=-1)  # Add channel dimension since it's grey scale\n",
    "\n",
    "        images.append(img)\n",
    "        filenames.append(filename)\n",
    "        \n",
    "    return np.array(images), filenames\n",
    "\n",
    "# Load ground truth masks from a folder\n",
    "def load_ground_truth_masks(folder, filenames, img_size=SEG_OUTPUT_SIZE): # masks are downsampled in the segmentation network so they need to be the same to compare\n",
    "    masks = []\n",
    "    for filename in filenames:\n",
    "        mask_path = os.path.join(folder, filename)\n",
    "        if os.path.exists(mask_path):\n",
    "\n",
    "            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)  # Convert to grayscale\n",
    "            mask = cv2.resize(mask, img_size)  # Resize to match test images\n",
    "            mask = mask.astype(np.float32) / 255.0  # Normalize to [0, 1]\n",
    "            mask = (mask > 0.5).astype(np.float32) # Binarize mask\n",
    "            mask = np.expand_dims(mask, axis=-1)  # Add channel dimension since it's grey scale\n",
    "            \n",
    "        else:\n",
    "            # If no ground truth mask exists, assume it's a good image (all zeros)\n",
    "            mask = np.zeros((img_size[0], img_size[1], 1))\n",
    "        masks.append(mask)\n",
    "\n",
    "    return np.array(masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANDOM SEEDS\n",
    "\n",
    "# Keep model seed fixed\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Change data split seed instead\n",
    "# to evaluate how the different data split affects performance\n",
    "# random_state=None in scikit-learn split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DATA\n",
    "\n",
    "# Paths to the folders\n",
    "abnormal_dir = os.path.join(ROOT_FOLDER, DATASET_FOLDER, DEFECT_TYPE_FOLDER, \"test_abnormal\") # Defective images\n",
    "mask_dir = os.path.join(ROOT_FOLDER, DATASET_FOLDER, DEFECT_TYPE_FOLDER, \"ground_truth\") # Ground truth masks\n",
    "normal_dir = os.path.join(ROOT_FOLDER, DATASET_FOLDER, DEFECT_TYPE_FOLDER, \"test_normal\") # Normal (good) images\n",
    "train_dir = os.path.join(ROOT_FOLDER, DATASET_FOLDER, DEFECT_TYPE_FOLDER, \"train\") # Train (good) images\n",
    "\n",
    "# Load training images\n",
    "train_images, _ = load_images_from_folder(train_dir)\n",
    "print(f\"# train_images: {len(train_images)}\")\n",
    "# Load defective test images and their ground truth masks\n",
    "defective_images, defective_filenames = load_images_from_folder(abnormal_dir)\n",
    "ground_truth_masks = load_ground_truth_masks(mask_dir, defective_filenames)\n",
    "print(f\"# ground_truth_masks: {len(ground_truth_masks)}\")\n",
    "# Load normal test images\n",
    "normal_images, _ = load_images_from_folder(normal_dir)\n",
    "# Combine defective and normal images for testing\n",
    "test_images = np.concatenate([defective_images, normal_images], axis=0)\n",
    "print(f\"# test_images: {len(test_images)}\")\n",
    "test_labels = np.concatenate([np.ones(len(defective_images)), np.zeros(len(normal_images))], axis=0)\n",
    "print(f\"# test_labels: {len(test_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHOW RANDOM DATA SAMPLES\n",
    "\n",
    "# Randomly select 2 defective and 2 normal samples\n",
    "num_samples = 2\n",
    "defective_indices = np.random.choice(len(defective_images), num_samples, replace=False)\n",
    "normal_indices = np.random.choice(len(normal_images), num_samples, replace=False)\n",
    "\n",
    "# Visualize random samples\n",
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "# Display 2 random defective images and their ground truth masks\n",
    "for i, idx in enumerate(defective_indices):\n",
    "    plt.subplot(2, 4, i + 1)\n",
    "    plt.imshow(defective_images[idx].squeeze(), cmap='gray')\n",
    "    plt.title(f\"Defective Image {idx}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2, 4, i + 5)\n",
    "    plt.imshow(ground_truth_masks[idx].squeeze(), cmap='gray')\n",
    "    plt.title(f\"Ground Truth Mask {idx}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "# Display 2 random normal images\n",
    "for i, idx in enumerate(normal_indices):\n",
    "    plt.subplot(2, 4, i + 3)\n",
    "    plt.imshow(normal_images[idx].squeeze(), cmap='gray')\n",
    "    plt.title(f\"Normal Image {idx}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2, 4, i + 7)\n",
    "    plt.imshow(np.zeros((128, 128)), cmap='gray')  # No mask for normal images\n",
    "    plt.title(\"No Mask (Normal)\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLIT DATA INTO TRAINING - VALIDATION\n",
    "\n",
    "val_size = 0.2  # 20% of the data for testing\n",
    "train_images, val_images, = train_test_split(\n",
    "    train_images,\n",
    "    test_size=val_size, \n",
    "    random_state=None # Random split\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARCHITECTURE (ORIGINAL PAPER + RESIDUAL BLOCKS +  A BIT DEEPER + DROPOUT + SMALL BOTTLENECK)\n",
    "\n",
    "def residual_block(x, filters, kernel=3):\n",
    "    # If dimensions don't match, adjust the shortcut\n",
    "    if x.shape[-1] != filters:\n",
    "        x = layers.Conv2D(filters, (1, 1), padding=\"same\")(x)\n",
    "    \n",
    "    # Residual path\n",
    "    y = layers.Conv2D(filters, kernel, padding=\"same\")(x)\n",
    "    y = layers.LeakyReLU(alpha=0.2)(y)\n",
    "    y = layers.Conv2D(filters, kernel, padding=\"same\")(y)\n",
    "\n",
    "    # Add shortcut\n",
    "    y = layers.add([x, y])\n",
    "    y = layers.LeakyReLU(alpha=0.2)(y)    \n",
    "    \n",
    "    return y\n",
    "\n",
    "def build_autoencoder(input_shape=INPUT_SHAPE, latent_dim=100):\n",
    "    # Encoder\n",
    "    encoder_input = layers.Input(shape=input_shape, name=\"encoder_input\")\n",
    "    \n",
    "    # Conv1: input_shape / 2\n",
    "    x = layers.Conv2D(32, (4, 4), strides=2, padding=\"same\")(encoder_input)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "    x = residual_block(x, 32, 3)  # Add a residual block\n",
    "    \n",
    "    # Conv2: input_shape / 4\n",
    "    x = layers.Conv2D(32, (4, 4), strides=2, padding=\"same\")(x)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "    x = residual_block(x, 32, 3)  # Add a residual block\n",
    "    \n",
    "    # Conv3: input_shape / 4\n",
    "    x = layers.Conv2D(64, (3, 3), strides=1, padding=\"same\")(x)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    # Conv4: input_shape / 8\n",
    "    x = layers.Conv2D(128, (4, 4), strides=2, padding=\"same\")(x)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "    x = residual_block(x, 128, 3)  # Add a residual block\n",
    "    \n",
    "    # Conv5: input_shape / 8\n",
    "    x = layers.Conv2D(128, (3, 3), strides=1, padding=\"same\")(x)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    # Conv6: input_shape / 16\n",
    "    x = layers.Conv2D(256, (4, 4), strides=2, padding=\"same\")(x)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "    x = residual_block(x, 256, 3)  # Add a residual block\n",
    "    \n",
    "    # Conv7: input_shape / 16\n",
    "    x = layers.Conv2D(128, (3, 3), strides=1, padding=\"same\")(x)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    # Conv8: input_shape / 16\n",
    "    x = layers.Conv2D(64, (3, 3), strides=1, padding=\"same\")(x)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    # Dropout\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    \n",
    "    # Final bottleneck layer 16 x 16 -> 3 x 3\n",
    "    encoder_output = layers.Conv2D(latent_dim, (12, 12), strides=2, padding=\"valid\",  activation=\"linear\")(x)\n",
    "    \n",
    "    encoder = models.Model(\n",
    "        inputs=encoder_input, \n",
    "        outputs=encoder_output,\n",
    "        name=\"encoder\"\n",
    "    )\n",
    "    \n",
    "    # Get encoder output shape for decoder input\n",
    "    encoder_output_shape = encoder.output.shape[1:]\n",
    "    \n",
    "    # Decoder\n",
    "    decoder_input = layers.Input(shape=encoder_output_shape, name=\"decoder_input\")\n",
    "    \n",
    "    # Reverse of Conv8 3 x 3 -> 16 x 16\n",
    "    x = layers.Conv2DTranspose(64, (12, 12), strides=2, padding=\"valid\")(decoder_input)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    # Reverse of Conv7\n",
    "    x = layers.Conv2DTranspose(128, (3, 3), strides=1, padding=\"same\")(x)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    # Reverse of Conv6    \n",
    "    x = layers.Conv2DTranspose(256, (4, 4), strides=1, padding=\"same\")(x)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)    \n",
    "    x = residual_block(x, 256, 3)  # Add a residual block\n",
    "    \n",
    "    # Reverse of Conv5\n",
    "    x = layers.Conv2DTranspose(128, (3, 3), strides=2, padding=\"same\")(x)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)    \n",
    "    \n",
    "    # Reverse of Conv4    \n",
    "    x = layers.Conv2DTranspose(128, (4, 4), strides=1, padding=\"same\")(x)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)  \n",
    "    x = residual_block(x, 128, 3)  # Add a residual block  \n",
    "    \n",
    "    # Reverse of Conv3\n",
    "    x = layers.Conv2DTranspose(64, (3, 3), strides=2, padding=\"same\")(x)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    # Reverse of Conv2    \n",
    "    x = layers.Conv2DTranspose(32, (4, 4), strides=1, padding=\"same\")(x)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)   \n",
    "    x = residual_block(x, 32, 3)  # Add a residual block \n",
    "    \n",
    "    # Reverse of Conv1    \n",
    "    x = layers.Conv2DTranspose(32, (4, 4), strides=2, padding=\"same\")(x)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "    x = residual_block(x, 32, 3)  # Add a residual block\n",
    "    \n",
    "    # Final output layer\n",
    "    decoder_output = layers.Conv2DTranspose(input_shape[-1], (4, 4), strides=2, padding=\"same\", activation=\"sigmoid\")(x)\n",
    "    \n",
    "    decoder = models.Model(\n",
    "        inputs=decoder_input,\n",
    "        outputs=decoder_output,\n",
    "        name=\"decoder\"\n",
    "    )\n",
    "    \n",
    "    return encoder, decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DCAE MODEL\n",
    "\n",
    "class DCAE(models.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(DCAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def call(self, inputs):\n",
    "        latent = self.encoder(inputs)\n",
    "        reconstructed = self.decoder(latent)\n",
    "        return reconstructed\n",
    "\n",
    "    def compile(self, optimizer, **kwargs):\n",
    "        super().compile(**kwargs)\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # Unpack the data since for unsupervised learning there are no labels\n",
    "        x = data if isinstance(data, tf.Tensor) else data[0]\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward pass\n",
    "            x_reconstructed = self(x, training=True)\n",
    "            # Compute SSIM loss (1 - SSIM)\n",
    "            ssim_loss = 1 - tf.reduce_mean(\n",
    "                tf.image.ssim(x, x_reconstructed, max_val=1.0)\n",
    "            )\n",
    "            # Compute MSE for comparison\n",
    "            mse_loss = tf.reduce_mean(tf.square(x - x_reconstructed))\n",
    "\n",
    "            # Weight the losses (adjust these weights based on experiments)\n",
    "            #combined_loss = 0.7 * ssim_loss + 0.3 * mse_loss\n",
    "        \n",
    "        # Compute gradients and update weights\n",
    "        gradients = tape.gradient(ssim_loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "        \n",
    "        # Return metrics\n",
    "        return {\n",
    "            \"loss\": ssim_loss,  # SSIM-based loss\n",
    "            \"ssim\": 1 - ssim_loss,  # SSIM metric (higher is better)\n",
    "            \"mse\": mse_loss,  # MSE metric (lower is better)\n",
    "        }\n",
    "    \n",
    "    def test_step(self, data):\n",
    "        # Unpack the data since for unsupervised learning there are no labels\n",
    "        x = data if isinstance(data, tf.Tensor) else data[0]\n",
    "        \n",
    "        # Compute reconstructions\n",
    "        x_reconstructed = self(x, training=False)\n",
    "        \n",
    "        # Compute SSIM loss\n",
    "        ssim_loss = 1 - tf.reduce_mean(\n",
    "            tf.image.ssim(x, x_reconstructed, max_val=1.0)\n",
    "        )\n",
    "        \n",
    "        # Compute MSE\n",
    "        mse_loss = tf.reduce_mean(tf.square(x - x_reconstructed))\n",
    "        \n",
    "        # Return metrics (same as train_step to ensure consistency)\n",
    "        return {\n",
    "            \"loss\": ssim_loss,\n",
    "            \"ssim\": 1 - ssim_loss,\n",
    "            \"mse\": mse_loss,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPILE THE MODEL\n",
    "\n",
    "# Create model instance\n",
    "# Build autoencoder\n",
    "encoder, decoder = build_autoencoder(input_shape=INPUT_SHAPE, latent_dim=LATENT_DIM)\n",
    "model = DCAE(encoder, decoder)\n",
    "\n",
    "# Compile model with Dice loss and coefficient metric\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001)  \n",
    ")\n",
    "\n",
    "# Print model summary\n",
    "# Summary of the architecture\n",
    "encoder.summary()\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN THE MODEL\n",
    "\n",
    "# Data augmentation (optional)\n",
    "datagen = ImageDataGenerator(\n",
    "    #rotation_range=10,\n",
    "    #width_shift_range=0.1,\n",
    "    #height_shift_range=0.1,\n",
    "    #shear_range=0.1,\n",
    "    #zoom_range=0.2,\n",
    "    vertical_flip=True,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Fit the data generator to your training data\n",
    "train_generator = datagen.flow(\n",
    "    train_images, train_images,  # For autoencoder, input = target\n",
    "    batch_size=16,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping_callback = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_ssim\",  # Monitor SSIM on validation data\n",
    "    patience=10,\n",
    "    mode=\"max\",         # Higher SSIM is better\n",
    "    restore_best_weights=True,\n",
    "    verbose=1,\n",
    ")\n",
    "# Learning rate reducer\n",
    "lr_reducer = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_ssim\",\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    mode=\"max\",\n",
    "    min_lr=1e-6,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train with validation data\n",
    "history = model.fit(\n",
    "    #train_generator,\n",
    "    train_images,\n",
    "    validation_data=(val_images, val_images),  # Validation needs both X and y\n",
    "    epochs=150, \n",
    "    steps_per_epoch=math.ceil(len(train_images) / 16),  # Needed when using a generator\n",
    "    callbacks=[\n",
    "        early_stopping_callback,\n",
    "        lr_reducer\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANALYZE TRAINING\n",
    "\n",
    "# Extract metrics from history object\n",
    "training_loss = history.history['loss']\n",
    "training_ssim = history.history['ssim']\n",
    "training_mse = history.history['mse']\n",
    "val_loss = history.history['val_loss']\n",
    "val_ssim = history.history['val_ssim']\n",
    "val_mse = history.history['val_mse']\n",
    "\n",
    "# Create figure with three subplots\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 3))\n",
    "\n",
    "# Plot training & validation loss\n",
    "ax1.plot(training_loss, label='loss', color='blue')\n",
    "ax1.plot(val_loss, label='val_loss', color='green')\n",
    "ax1.set_title('Loss')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Plot training & validation accuracy\n",
    "ax2.plot(training_ssim, label='ssim', color='blue')\n",
    "ax2.plot(val_ssim, label='val_ssim', color='green')\n",
    "ax2.set_title('SSIM')\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.legend()\n",
    "ax2.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Plot training & validation accuracy\n",
    "ax3.plot(training_mse, label='mse', color='blue')\n",
    "ax3.plot(val_mse, label='val_mse', color='green')\n",
    "ax3.set_title('MSE')\n",
    "ax3.set_xlabel('Epochs')\n",
    "ax3.set_ylabel('Accuracy')\n",
    "ax3.legend()\n",
    "ax3.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Adjust layout and display\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANOMALY SCORE\n",
    "\n",
    "def calculate_anomaly_score(image, dcae):\n",
    "    # Generate the reconstructed image DCAE(x)\n",
    "    image_batch = tf.expand_dims(image, axis=0)\n",
    "    reconstructed_batch = dcae(image_batch)\n",
    "    reconstructed_image = tf.squeeze(reconstructed_batch, axis=0)\n",
    "\n",
    "    anomaly_score = tf.reduce_mean(tf.square(image - reconstructed_image)) # ME DA MEJORES NÚMEROS\n",
    "\n",
    "    anomaly_map = tf.sqrt(tf.square(image - reconstructed_image))\n",
    "\n",
    "    #anomaly_map = tf.abs(image - reconstructed_image) # For when anomaly maps are black\n",
    "    \n",
    "    # Optionally compute SSIM and PSNR with slightly better parameters\n",
    "    ssim_score = ssim(\n",
    "        image, \n",
    "        reconstructed_image.numpy(), \n",
    "        win_size=7,  # Increased from 3 for better structural assessment\n",
    "        channel_axis=-1,\n",
    "        data_range=1.0\n",
    "    )\n",
    "    psnr_score = psnr(image, reconstructed_image.numpy(), data_range=1.0)\n",
    "    \n",
    "    return reconstructed_image, anomaly_map, anomaly_score, ssim_score, psnr_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIND BEST ANOMALY THRESHOLD (+ ACCURACY)\n",
    "\n",
    "j = 0\n",
    "step = 0.0001  \n",
    "limit =  0.1\n",
    "\n",
    "best_acc = 0\n",
    "best_prec = 0\n",
    "best_rec = 0\n",
    "best_f1 = 0\n",
    "best_fpr = 1\n",
    "best_weighted_mean = 0\n",
    "best_t = j\n",
    "\n",
    "# Evaluate on test images\n",
    "generated_images = []\n",
    "anomaly_maps = []\n",
    "anomaly_scores = []\n",
    "ssim_scores = []\n",
    "psnr_scores = []\n",
    "\n",
    "for i, img in enumerate(test_images):\n",
    "    generated_image, anomaly_map, anomaly_score, ssim_score, psnr_score = calculate_anomaly_score(img, model)\n",
    "    generated_images.append(generated_image)\n",
    "    anomaly_maps.append(anomaly_map)\n",
    "    anomaly_scores.append(anomaly_score)\n",
    "    ssim_scores.append(ssim_score)\n",
    "    psnr_scores.append(psnr_score)\n",
    "\n",
    "while j < limit: \n",
    "\n",
    "    # Compute AUC score\n",
    "    auc_score = roc_auc_score(test_labels, anomaly_scores) # use raw decision scores for ROC AUC\n",
    "\n",
    "    # Set a threshold for anomaly detection\n",
    "    predictions = (np.array(anomaly_scores) > j).astype(int)\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm_values = confusion_matrix(test_labels, predictions)\n",
    "    tn, fp, fn, tp = confusion_matrix(test_labels, predictions).ravel()\n",
    "    fpr = 0 if (fp + tn) == 0 else fp / (fp + tn)\n",
    "\n",
    "    # Compute additional metrics\n",
    "    accuracy = accuracy_score(test_labels, predictions)\n",
    "    precision = precision_score(test_labels, predictions, zero_division=0)\n",
    "    recall = recall_score(test_labels, predictions, zero_division=0)\n",
    "    f1 = f1_score(test_labels, predictions, zero_division=0)\n",
    "\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0  # Same as 1-FPR\n",
    "    # Weighted harmonic mean - gives more weight to accuracy\n",
    "    w_acc = 2\n",
    "    w_spec = 1\n",
    "    # Weighted arithmetic mean\n",
    "    weighted_mean = (w_acc * accuracy + w_spec * specificity) / (w_acc + w_spec)\n",
    "\n",
    "    #if weighted_mean > best_weighted_mean:    \n",
    "    if accuracy > best_acc:      \n",
    "\n",
    "        best_acc = accuracy \n",
    "        best_prec = precision \n",
    "        best_rec = recall \n",
    "        best_f1 = f1 \n",
    "        best_fpr = fpr\n",
    "        #best_weighted_mean = weighted_mean\n",
    "        best_t = j\n",
    "\n",
    "    j += step    \n",
    "\n",
    "# Show evaluation metrics\n",
    "\"\"\"print(f\"Accuracy: {best_acc:.4f}\")\n",
    "print(f\"Precision: {best_prec:.4f}\")\n",
    "print(f\"Recall: {best_rec:.4f}\")\n",
    "print(f\"F1 Score: {best_f1:.4f}\")\n",
    "print(f\"FPR: {best_fpr:.4f}\")\n",
    "print(f\"weighted_mean: {best_weighted_mean:.4f}\")\"\"\"\n",
    "\n",
    "print(f\"\\nt: {best_t:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANOMALY_THRESHOLD = 0.0144 # Adjust this value based on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INFERENCE AND EVALUATION METRICS\n",
    "\n",
    "# Evaluate on test images\n",
    "generated_images = []\n",
    "anomaly_maps = []\n",
    "anomaly_scores = []\n",
    "ssim_scores = []\n",
    "psnr_scores = []\n",
    "\n",
    "for i, img in enumerate(test_images):\n",
    "    generated_image, anomaly_map, anomaly_score, ssim_score, psnr_score = calculate_anomaly_score(img, model)\n",
    "    generated_images.append(generated_image)\n",
    "    anomaly_maps.append(anomaly_map)\n",
    "    anomaly_scores.append(anomaly_score)\n",
    "    ssim_scores.append(ssim_score)\n",
    "    psnr_scores.append(psnr_score)\n",
    "\n",
    "# Compute AUC score\n",
    "auc_score = roc_auc_score(test_labels, anomaly_scores) # use raw decision scores for ROC AUC\n",
    "\n",
    "# Set a threshold for anomaly detection\n",
    "predictions = (np.array(anomaly_scores) > ANOMALY_THRESHOLD).astype(int)\n",
    "\n",
    "# Confusion matrix\n",
    "cm_values = confusion_matrix(test_labels, predictions)\n",
    "tn, fp, fn, tp = confusion_matrix(test_labels, predictions).ravel()\n",
    "fpr = fp / (fp + tn)\n",
    "\n",
    "# Compute additional metrics\n",
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "precision = precision_score(test_labels, predictions)\n",
    "recall = recall_score(test_labels, predictions)\n",
    "f1 = f1_score(test_labels, predictions)\n",
    "\n",
    "# Show evaluation metrics\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"FPR: {fpr:.4f}\")\n",
    "\n",
    "print(f\"AUROC: {auc_score:.4f}\")\n",
    "print(f\"Mean SSIM: {np.mean(ssim_scores):.4f}\")\n",
    "print(f\"Mean PSNR: {np.mean(psnr_scores):.4f}\")\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(4, 3))\n",
    "sns.heatmap(cm_values, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Normal', 'Anomaly'],\n",
    "            yticklabels=['Normal', 'Anomaly'])\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.title('Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZE RESULTS\n",
    "\n",
    "# Get indices of normal and anomalous samples\n",
    "normal_indices = np.where(test_labels == 0)[0]\n",
    "anomalous_indices = np.where(test_labels == 1)[0]\n",
    "\n",
    "# Randomly sample 5 normal and 5 anomalous examples\n",
    "#np.random.seed(42)  # for reproducibility\n",
    "random_normal_indices = np.random.choice(normal_indices, size=5, replace=False)\n",
    "random_anomalous_indices = np.random.choice(anomalous_indices, size=5, replace=False)\n",
    "\n",
    "# Combine them\n",
    "random_indices = np.concatenate([random_normal_indices, random_anomalous_indices])\n",
    "\n",
    "# Visualize random samples (5 normal and 5 anomalous)\n",
    "plt.figure(figsize=(25, 12))\n",
    "for i, idx in enumerate(random_indices):\n",
    "    # First row: original image\n",
    "    plt.subplot(4, 10, i + 1)\n",
    "    plt.imshow(test_images[idx], cmap='gray')\n",
    "    plt.title(\n",
    "        f\"Anomaly Score: {anomaly_scores[idx]:.4f}\\n\"\n",
    "        f\"Prediction: {'anomalous' if predictions[idx] == 1 else 'normal'}\\n\"\n",
    "        f\"Ground Truth: {'anomalous' if test_labels[idx] == 1 else 'normal'}\"\n",
    "    )\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Second row: ground truth mask\n",
    "    plt.subplot(4, 10, i + 11)\n",
    "    if test_labels[idx] == 1:  # Defective image\n",
    "        mask = ground_truth_masks[idx].squeeze()\n",
    "        plt.imshow(mask, cmap='gray')\n",
    "    else:  # Normal image\n",
    "        plt.imshow(np.zeros((128, 128)), cmap='gray')\n",
    "    plt.title(\"Ground truth mask\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Third row: generated image G(E(x))\n",
    "    plt.subplot(4, 10, i + 21)\n",
    "    plt.imshow(generated_images[idx], cmap='gray' if COLOR_IMAGES == False else None)\n",
    "    plt.title(\"Generated image\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Fourth row: anomaly map\n",
    "    plt.subplot(4, 10, i + 31)\n",
    "    plt.imshow(anomaly_maps[idx], cmap='jet')\n",
    "    plt.title(\"Anomaly map\")\n",
    "    plt.axis('off')\n",
    "\n",
    "# Add overall titles for normal and anomalous sections\n",
    "plt.figtext(0.25, 0.98, 'Random Normal Examples', fontsize=16, ha='center')\n",
    "plt.figtext(0.75, 0.98, 'Random Anomalous Examples', fontsize=16, ha='center')\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])  # Adjust layout to make room for the overall titles\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
